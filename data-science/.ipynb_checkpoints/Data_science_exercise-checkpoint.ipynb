{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagup Data Science Exercise\n",
    "\n",
    "ExampleCo, Inc is gathering several types of data for its fleet of very expensive machines.  These very expensive machines have three operating modes: *normal*, *faulty* and *failed*.   The machines run all the time, and usually they are in normal mode.  However, in the event that the machine enters faulty mode, the company would like to be aware of this as soon as possible.  This way they can take preventative action to avoid entering failed mode and hopefully save themselves lots of money.\n",
    "\n",
    "They collect four kinds of timeseries data for each machine in their fleet of very expensive machines.  When a machine is operating in *normal* mode the data behaves in a fairly predictable way, but with a moderate amount of noise.  Before a machine fails it will ramp into *faulty* mode, during which the data appears visibly quite different.  Finally, when a machine fails it enters a third, and distinctly different, *failed* mode where all signals are very close to 0.\n",
    "\n",
    "You can download the data here: [exampleco_data](https://drive.google.com/open?id=1b12u6rzkG1AxB6wLGl7IBVoaoSoZLHNR)\n",
    "\n",
    "__Your main objective: to develop an automated method to pinpoint the times of fault and failure in this machine__.  Keep in mind that you will be sharing these results with the executives at ExampleCo, so to the best of your ability, try to explain what you are doing, what you've shown, and why you think your predictions are good.\n",
    "\n",
    "\n",
    "A few notes to help:\n",
    "1. A good place to start is by addressing the noise due to communication\n",
    "   errors.\n",
    "2. Feel free to use any libraries you like, or even other programming\n",
    "   languages. Your final results should be presented in this notebook, however.\n",
    "3. There are no constraints on the techniques you bring to bear, we are curious\n",
    "   to see how you think and what sort of resources you have in your toolbox.\n",
    "4. Be sure to clearly articulate what you did, why you did it, and how the\n",
    "   results should be interpreted. In particular you should be aware of the\n",
    "   limitations of whatever approach or approaches you take.\n",
    "5. Don't feel compelled to use all the data if you're not sure how. Feel free\n",
    "   to focus on data from a single unit if that makes it easier to get started.\n",
    "6. Don't hesitate to reach out to datasciencejobs@tagup.io with any questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help you get started...\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from changepoint.variance_shift_model import VarianceShiftModel\n",
    "import os\n",
    "from scipy import interpolate\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/exampleco_data/machine_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,6))\n",
    "plt.plot(range(len(data)), data.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,6))\n",
    "plt.plot(range(len(data)), data.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,6))\n",
    "plt.plot(range(len(data)), data.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,6))\n",
    "plt.plot(range(len(data)), data.iloc[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the signals plotted above, we see that there is a change in variance when it changes from faulty to failure. We are essentially trying to capture that mode, since this is what is important to the business.\n",
    "\n",
    "### Solution:\n",
    "Here, we go over the solution for one of the machines. The basic idea is to first clean the signal and then detect a variance shift for each signal. Now, we take a look at each of the signal individually and report the earliest time where there was a variance shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_values_without_outliers(signal, threshold):\n",
    "    '''\n",
    "    Use median values to fill the outliers.\n",
    "    '''\n",
    "    sig_no_out = signal.apply(lambda x: x if (abs(x) < threshold) else None)\n",
    "    sig_no_out = [x for x in sig_no_out if x]\n",
    "    med_val =  np.nanmedian(sig_no_out)\n",
    "    # Filling the outliers with median values\n",
    "    sig_no_out = signal.apply(lambda x: x if (pd.isna(x)==False) and (abs(x) < threshold) else med_val)\n",
    "    return sig_no_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(A, threshold):\n",
    "    '''\n",
    "    interpolate to fill nan values\n",
    "    '''\n",
    "    A = A.apply(lambda x: x if (abs(x) < threshold) else None)\n",
    "    A = A.values\n",
    "    inds = np.arange(A.shape[0])\n",
    "    good = np.where(np.isfinite(A))\n",
    "    f = interpolate.interp1d(inds[good], A[good],kind=\"nearest\", bounds_error=False)\n",
    "    B = np.where(np.isfinite(A),A,f(inds))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Remove the data points due to communication errors.\n",
    "I currently have two approaches to remove the data points. One is to interpolate using median values and the other is to interpolate with nearest values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots after filling with median value\n",
    "1. we consider the threshold value to be 100. Datapoints that have an absolute value greater than 100 are considered to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 100\n",
    "def plot_median(signal):\n",
    "    filtered_sig = med_values_without_outliers(signal, THRESHOLD)\n",
    "    plt.figure(figsize=(26,6))\n",
    "    plt.plot(range(len(signal)), filtered_sig)\n",
    "\n",
    "data.iloc[:, 1:].reset_index(drop=True).apply(lambda x: plot_median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "We see that the rest of the noise is cleaned. Except for signal 3, we see that the rest of the signals have a clear variance shift in their signal.There will be a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots after interpolating with nearest values\n",
    "1. we consider the threshold value to be 100. Datapoints that have an absolute value greater than 100 are considered to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 100\n",
    "def plot_interpolated(signal):\n",
    "    filtered_sig = fill_nan(signal, THRESHOLD)\n",
    "    plt.figure(figsize=(26,6))\n",
    "    plt.plot(range(len(signal)), filtered_sig)\n",
    "\n",
    "data.iloc[:, 1:].reset_index(drop=True).apply(lambda x: plot_interpolated(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "\n",
    "1. Both methods produce similar outputs. Hence, we proceed on to use interpolation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filename = './model/changepoint_model.pkl'\n",
    "\n",
    "if 'changepoint_model.pkl' not in os.listdir('./model/'):\n",
    "    \n",
    "else:\n",
    "    infile = open(filename,'rb')\n",
    "    model = pickle.load(infile)\n",
    "    infile.close()\n",
    "'''\n",
    "    \n",
    "model = VarianceShiftModel(50,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_cleaned = data.iloc[:, 1:].reset_index(drop=True).apply(lambda x: med_values_without_outliers(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal1_result = model.offlineDetection(signal_cleaned.iloc[:, 0].values, omit_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal2_result = model.offlineDetection(signal_cleaned.iloc[:, 1].values, omit_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal3_result = model.offlineDetection(signal_cleaned.iloc[:, 2].values, omit_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal4_result = model.offlineDetection(signal_cleaned.iloc[:, 3].values, omit_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "filename = './model/changepoint_model.pkl'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(model, outfile)\n",
    "outfile.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Threshold statistic above which we flag a variance shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Null threshold Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.null_threshold_distribution)\n",
    "plt.axvline(x=model.threshold, color=\"red\")\n",
    "plt.text(model.threshold, 150, r' Threshold with 1% designed false positive rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we take the minimum of all the breakpoints and get the timestamp of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_fault_index = min(signal1_result.breakpoints[0], signal2_result.breakpoints[0], signal3_result.breakpoints[0], signal4_result.breakpoints[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_fault_time = data.iloc[min_fault_index, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_fault_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the earliest time where the machine failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we automate this for all the machines . \n",
    "\n",
    "Run the below script to automate the process for all machines. The results are stored in a csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh start.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect frequency shift \n",
    "1. The initial idea was to detect frequency shift using stft\n",
    "2. It looks the normal mode has two fundamental frequencies and when it goes to faulty, there's a multitude of frequencies.\n",
    "3. Messed up the time axis when i converted to seconds.Had difficulties while getting the original timestamp back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1/ ((60*60*8)) #Each signal is 8 hrs apart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/exampleco_data/machine_5.csv')\n",
    "signal_cleaned = data.iloc[:, 1:].reset_index(drop=True).apply(lambda x: med_values_without_outliers(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, time, mag = signal.stft(signal_cleaned.iloc[:,0], fs)\n",
    "plt.figure(figsize=(26,6))\n",
    "plt.pcolormesh(time, freq, np.abs(mag))\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, time, mag = signal.stft(signal_cleaned.iloc[:,1], fs)\n",
    "plt.figure(figsize=(26,6))\n",
    "plt.pcolormesh(time, freq, np.abs(mag))\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, time, mag = signal.stft(signal_cleaned.iloc[:,2], fs)\n",
    "plt.figure(figsize=(26,6))\n",
    "plt.pcolormesh(time, freq, np.abs(mag))\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, time, mag = signal.stft(signal_cleaned.iloc[:,3], fs)\n",
    "plt.figure(figsize=(26,6))\n",
    "plt.pcolormesh(time, freq, np.abs(mag))\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
